# -*- coding: utf-8 -*-
"""vector_database_begineer_to_advanced.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11ok-SIzChjOWl_ESkspOZnWPZp7pY-4h

## import all necessary libraries
"""

"""
FIXED RAG SYSTEM - ADDRESSING CONTEXT WINDOW ISSUES
- Optimized for Flan-T5 limitations
- Smaller, more focused chunks
- Simplified prompts to maximize context space
- Better chunk filtering and ranking
"""

import os
import re
import warnings
from typing import List, Dict, Any, Tuple
import numpy as np

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.llms import HuggingFacePipeline
from transformers import pipeline
import torch

warnings.filterwarnings("ignore")

"""## step 2 there we will remove special charcters, white spaces ........."""

def smart_text_preprocessing(self, text: str) -> str:
        """Intelligent preprocessing that preserves meaning"""
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^a-zA-Z0-9\s\.\,\!\?\-\(\)\[\]\{\}\:\;]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

"""## here we will optimize and upload the pdf"""

def load_and_process_documents(self):
        """Load PDFs with optimized processing"""
        print("ğŸ“š Loading documents...")

        # Directly set PDF folder here
        self.pdf_folder = "/content/x"

        if not os.path.exists(self.pdf_folder):
            raise ValueError(f"PDF folder not found: {self.pdf_folder}")

        pdf_files = [f for f in os.listdir(self.pdf_folder) if f.endswith('.pdf')]
        if not pdf_files:
            raise ValueError(f"No PDF files found in {self.pdf_folder}")

        for filename in pdf_files:
            try:
                loader = PyPDFLoader(os.path.join(self.pdf_folder, filename))
                docs = loader.load()

                for doc in docs:
                    doc.metadata["source_file"] = filename
                    doc.page_content = self.smart_text_preprocessing(doc.page_content)

                self.documents.extend(docs)
                print(f"ğŸ“„ Loaded: {filename}")

            except Exception as e:
                print(f"âŒ Error loading {filename}: {e}")

"""## optimize the dataset using chunks i make a small chunks for this"""

def create_optimized_chunks(self):
        """Create SMALL chunks for Flan-T5's limited context window"""
        print("âœ‚ï¸ Creating optimized chunks...")

        # MUCH SMALLER chunks for Flan-T5
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=400,      # Small enough for Flan-T5 context
            chunk_overlap=50,    # Minimal overlap
            separators=["\n\n", "\n", ". ", "! ", "? ", ", ", " ", ""],
            length_function=len
        )

        self.chunks = splitter.split_documents(self.documents)

        # Filter out tiny chunks
        filtered_chunks = []
        for i, chunk in enumerate(self.chunks):
            if len(chunk.page_content) > 50:  # Only meaningful chunks
                chunk.metadata["chunk_id"] = i
                chunk.metadata["chunk_length"] = len(chunk.page_content)
                filtered_chunks.append(chunk)

        self.chunks = filtered_chunks
        print(f"âœ… Created {len(self.chunks)} optimized chunks")

        avg_length = np.mean([len(chunk.page_content) for chunk in self.chunks])
        print(f"ğŸ“Š Average chunk length: {avg_length:.0f} characters")

"""## create a vectore database using faiss(secure and fast in offline )"""

def create_vector_database(self):
        """Create vector database"""
        print("ğŸ” Creating vector database...")
        self.vectorstore = FAISS.from_documents(self.chunks, self.embeddings)
        print("âœ… Vector database created!")

"""## retrieve the data"""

def create_retrievers(self):
        """Create optimized retrievers"""
        print("ğŸ”¤ Creating retrievers...")

        # BM25 for keyword matching
        self.bm25_retriever = BM25Retriever.from_documents(self.chunks)
        self.bm25_retriever.k = 3  # Fewer chunks to preserve context space

        # FAISS for semantic search
        faiss_retriever = self.vectorstore.as_retriever(search_kwargs={"k": 3})

        # Ensemble with equal weights
        self.ensemble_retriever = EnsembleRetriever(
            retrievers=[self.bm25_retriever, faiss_retriever],
            weights=[0.5, 0.5]
        )
        print("âœ… Retrievers created!")

"""##  Create QA chain with MINIMAL prompt for maximum context space"""

def create_qa_chain(self):

        print("ğŸ”— Creating QA chain...")

        # ULTRA-SHORT prompt to save context space
        template = """Context: {context}

Question: {question}

Answer based only on the context above:"""

        prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )

        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.ensemble_retriever,
            chain_type_kwargs={"prompt": prompt},
            return_source_documents=True,
            verbose=False
        )

        print("âœ… QA chain created!")

"""## this use for find good chunks"""

def smart_context_selection(self, question: str, retrieved_docs: List) -> str:
        """Select best context chunks to fit in model's context window"""

        combined_context = ""
        max_context_chars = 800  # Conservative limit for Flan-T5

        for doc in retrieved_docs[:4]:  # Max 4 chunks
            chunk_text = doc.page_content
            if len(combined_context) + len(chunk_text) < max_context_chars:
                combined_context += chunk_text + "\n\n"
            else:
                break

        return combined_context.strip()

"""## for ans"""

def ask(self, question: str) -> Dict[str, Any]:
        """Ask question with optimized context handling"""

        try:
            # Get raw retrieval results first
            retrieved_docs = self.ensemble_retriever.get_relevant_documents(question)

            # Select best context within token limits
            optimized_context = self.smart_context_selection(question, retrieved_docs)

            # Create focused prompt
            focused_prompt = f"""Context: {optimized_context}

Question: {question}

Answer based only on the context above:"""

            # Generate answer directly
            answer = self.llm.predict(focused_prompt)

            return {
                "question": question,
                "answer": answer,
                "sources": [
                    {
                        "source_file": doc.metadata.get("source_file", "Unknown"),
                        "page": doc.metadata.get("page", "Unknown"),
                        "content_preview": doc.page_content[:150] + "..."
                    }
                    for doc in retrieved_docs[:3]
                ],
                "num_sources": len(retrieved_docs)
            }

        except Exception as e:
            return {
                "question": question,
                "answer": f"Error: {str(e)}",
                "sources": [],
                "num_sources": 0
            }

"""## setup is correct or not"""

def setup_complete_system(self):
        """Setup complete optimized system"""
        print("ğŸš€ Setting up optimized RAG system...")
        print("=" * 50)

        self.load_and_process_documents()
        self.create_optimized_chunks()
        self.create_vector_database()
        self.create_retrievers()
        self.create_qa_chain()

        print("=" * 50)
        print("ğŸ‰ Optimized RAG system ready!")
        print(f"ğŸ“Š {len(self.chunks)} chunks ready for Q&A")

"""## question ans session"""

def interactive_session(self):
        """Interactive Q&A session"""
        print("\nğŸ¤– Starting interactive session...")
        print("Type 'quit' to exit")
        print("-" * 40)

        while True:
            try:
                question = input("\nâ“ Your question: ").strip()

                if question.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ Goodbye!")
                    break
                elif not question:
                    continue

                print("ğŸ” Searching...")
                response = self.ask(question)

                print(f"\nğŸ’¡ Answer:")
                print(response["answer"])

                print(f"\nğŸ“š Sources ({response['num_sources']} found):")
                for i, source in enumerate(response["sources"], 1):
                    print(f"  {i}. {source['source_file']} (Page {source['page']})")
                    print(f"     {source['content_preview']}")

                print("-" * 40)

            except KeyboardInterrupt:
                print("\nğŸ‘‹ Goodbye!")
                break
            except Exception as e:
                print(f"âŒ Error: {e}")

"""## main file"""

def main():
    """Main function"""
    PDF_FOLDER = "/content/x"  # Change to your PDF folder

    try:
        print("ğŸš€ OPTIMIZED RAG SYSTEM FOR SMALL MODELS")
        print("=" * 50)

        rag_system = OptimizedRAGSystem(PDF_FOLDER)
        rag_system.setup_complete_system()

        # Quick test
        test_questions = [
            "What is Agent-E system?",
            "How does neural network work?",
            "Explain reinforcement learning"
        ]

        print("\nğŸ§ª Quick test...")
        for question in test_questions[:1]:
            print(f"\nğŸ“ Testing: {question}")
            response = rag_system.ask(question)
            print(f"ğŸ’¡ Answer: {response['answer'][:100]}...")

        # Start interactive session
        rag_system.interactive_session()

    except Exception as e:
        print(f"âŒ Error: {e}")
        print("\nğŸ’¡ Make sure:")
        print("1. PDF folder path is correct")
        print("2. PDFs exist in folder")
        print("3. All libraries installed")

if __name__ == "__main__":
    main()

